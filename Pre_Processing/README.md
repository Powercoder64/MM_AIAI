# I3D-Based Video Feature Pre-Processing ğŸš€
Convert raw **`.mp4` videos â†’ NumPy feature tensors** ready for multimodal / actionâ€‘recognition pipelines.  
This module lives in **`MM_AIAI/Pre_Processing/`** and extracts **RGB** and **opticalâ€‘flow** embeddings with an *Inflatedâ€‘3â€‘DÂ (I3D)* backbone, using **PWCâ€‘Net** for dense flow.

---

## ğŸ“‘ Table of Contents
1. [Features](#features)
2. [QuickÂ Start](#quick-start)
3. [Outputs](#outputs)
4. [ProjectÂ Structure](#project-structure)
5. [Configuration](#configuration)
6. [Dependencies](#dependencies)
7. [Preâ€‘TrainedÂ Weights](#pre-trained-weights)

---

## âœ¨ Features
- **Oneâ€‘liner inference:** `python Pre_Processing.py filename=<video.mp4>`
- **Dualâ€‘stream I3D** (RGBÂ +Â Flow) with PWCâ€‘Net flow estimation  
- Customisable **input / output folders**, FPS, clip length, device IDs  
- Produces four artefacts; only `*_rgb.npy` and `*_flow.npy` are mandatory for the subsequent multimodal model

---

## ğŸš€ Quick Start

### 1 Â· Clone the parent project
```bash
git clone https://github.com/Powercoder64/MM_AIAI.git
cd MM_AIAI
```

### 2 Â· Build the Docker image *(from the subâ€‘folder)*
```bash
docker build -t pre-process \
             -f Pre_Processing/Dockerfile \
             Pre_Processing
```

### 3 Â· Run the extractor
```bash
# Prepare folders & copy a video
mkdir -p Pre_Processing/video Pre_Processing/output
cp /path/to/my_clip.mp4 Pre_Processing/video/

docker run --gpus all \
           -v $(pwd)/Pre_Processing/video:/app/video \
           -v $(pwd)/Pre_Processing/output:/app/output \
           pre-process \
           python Pre_Processing.py filename=my_clip.mp4
```

### 4 Â· Run locally (conda / pip)
```bash
cd Pre_Processing
conda env create -f conda_env_torch_zoo.yml
conda activate torch_zoo

python Pre_Processing.py filename=my_clip.mp4
```

---

## ğŸ“¦ Outputs
| File (for `my_clip`)        | Tensor shape | Description                                |
|-----------------------------|--------------|--------------------------------------------|
| `my_clip_rgb.npy`           | `(T, 1024)`  | **_*feed to multimodal model*_**           |
| `my_clip_flow.npy`          | `(T, 1024)`  | **_*feed to multimodal model*_**           |
| `my_clip_rgb_frames.npy`    | `(N,H,W,3)`  | (optional) decoded RGB frames              |
| `my_clip_flow_frames.npy`   | `(N,H,W,2)`  | (optional) raw optical flow (PWCâ€‘Net)      |

Only the first two files are required by the next multimodal stage.

---

## ğŸ—‚ Project Structure
```text
MM_AIAI/
â””â”€â”€ Pre_Processing/
    â”œâ”€â”€ Pre_Processing.py               # entry point
    â”‚
    â”œâ”€â”€ Dockerfile                      # Docker build file
    â”‚
    â”œâ”€â”€ utils/
    â”‚   â””â”€â”€ utils.py                    # path_list = './video/' + args.filename
    â”‚
    â”œâ”€â”€ models/
    â”‚   â”œâ”€â”€ i3d/
    â”‚   â”‚   â”œâ”€â”€ extract_i3d.py          # self.output_path = './output/'
    â”‚   â”‚   â””â”€â”€ checkpoints/
    â”‚   â”‚       â”œâ”€â”€ i3d_rgb.pt
    â”‚   â”‚       â””â”€â”€ i3d_flow.pt
    â”‚   â””â”€â”€ pwc/
    â”‚       â”œâ”€â”€ extract_pwc.py
    â”‚       â””â”€â”€ checkpoints/
    â”‚           â””â”€â”€ pwc_net_sintel.pt
    â”‚
    â””â”€â”€ configs/                        # frameâ€‘rate & clipâ€‘length YAMLs
```
> **Keep the checkpoint folders exactly as shown** so the loader can find the `.pt` files.

---

## âš™ï¸ Configuration
| Parameter         | Default     | How to change                                                                                   |
|-------------------|-------------|-------------------------------------------------------------------------------------------------|
| Video folder      | `./video/`  | Edit **`utils/utils.py`** â†’ `path_list = './video/' + args.filename`                            |
| Output folder     | `./output/` | Edit **`models/i3d/extract_i3d.py`** â†’ `self.output_path = './output/'`                         |
| FPS / clip length | see YAMLs   | Tweak files in **`configs/`**                                                                   |

---

## ğŸ“š Dependencies
*(Full list in the Dockerfile & Conda YAML)*
| Package                        | Purpose                                |
|--------------------------------|----------------------------------------|
| **PyTorch â‰¥Â 1.7 + CUDA**       | Deep learning & GPU compute            |
| **torchvision**                | I3D layers & video transforms          |
| **opencv-python**              | Video decoding                         |
| **ffmpeg / av**                | Extra container formats                |
| **numpy**, **pandas**          | Tensor & log handling                  |
| **scikit-learn**               | Evaluation utilities                   |

---

## ğŸ“¥ Preâ€‘Trained Weights
```bash
unzip pp_models.zip -d tmp_pp_models

# move the files into place
mv tmp_pp_models/i3d_rgb.pt   Pre_Processing/models/i3d/checkpoints/
mv tmp_pp_models/i3d_flow.pt  Pre_Processing/models/i3d/checkpoints/
mv tmp_pp_models/pwc_net_sintel.pt Pre_Processing/models/pwc/checkpoints/

# clean up
rm -r tmp_pp_models
```
Resulting tree:
```text
models/
â”œâ”€â”€ i3d/checkpoints/i3d_rgb.pt
â”œâ”€â”€ i3d/checkpoints/i3d_flow.pt
â””â”€â”€ pwc/checkpoints/pwc_net_sintel.pt
```
